# Early-Detection-of-Heart-Disease-Using-Machine-Learning


ğŸ“„ Final Status Report
**Heart Disease Classification Project**

---

ğŸ· **Project Title**
**Classification of Heart Disease Using Machine Learning and Ensemble Models**

ğŸ‘¤ **Student Name**
**Mohamed Mesbah & Aymen Mildi**

ğŸ§¾ **Course**
**CS461 - Machine Learning**

---

ğŸŸ© **Weekly Progress Summary**

âœ… **This Weekâ€™s Accomplishments**

- Completed implementation of data preprocessing using:
  - One-Hot Encoding
  - Standard Scaling
- Built evaluation modules using:
  - Hold-out Train/Test Split
  - K-Fold Cross-Validation
  - Stratified K-Fold Cross-Validation
- Integrated a wide range of ensemble models, including:
  - `StackingClassifier`
  - Voting (Hard & Soft)
  - Bagging (with KNN, DecisionTree)
  - Random Forest, Gradient Boosting
- Extracted and reported multiple performance metrics:
  - Accuracy, Precision, Recall, F1-score
  - ROC-AUC, MCC, Cohen-Kappa
  - Confusion Matrix
- Visualizations:
  - Boxplot: Cross-validation score distribution
  - Bar chart: Accuracy vs. ROC-AUC across models
  - Heatmaps: Confusion matrices

---

ğŸ•’ **Are You On Schedule?**
âœ… Yes â€“ The project is on track. All planned features for the mid-project milestone were implemented successfully.

---

ğŸ“ **Milestones Met**â˜‘ Data Cleaning & Preprocessingâ˜‘ Modular code structure:

- `data_preparation.py`
- `model_training.py`
- `ensemble_models.py`
  â˜‘ Evaluation of multiple individual and ensemble classifiers
  â˜‘ Mid-project reporting and visualization

---

ğŸ“Š **Midway Results Summary**

- **Best individual model (so far):**
  - Logistic Regression â€” Accuracy â‰ˆ **87%**, ROC-AUC â‰ˆ **89%**
- **Best ensemble model:**
  - Voting (Soft) or Gradient Boosting â€” Accuracy â‰ˆ **88â€“90%**, ROC-AUC â‰ˆ **91%**
- **Confusion matrix heatmaps:**
  - Show more true positives than false negatives â€” favorable for medical diagnostic applications.

---

ğŸ“Œ **Upcoming Milestones & Plans**

ğŸ”¬ **Experiments in Progress**

- Hyperparameter tuning via `GridSearchCV`
- Evaluation using external datasets (e.g., Cleveland dataset)
- Plotting ROC and Precision-Recall (PR) curves
- Testing under imbalanced data scenarios

ğŸ§ª **Planned Experiments**

- Compare ensemble robustness across varying `StratifiedKFold` seeds
- Use **SHAP** or permutation importance for interpretability
- Detect overfitting: Compare training vs. validation metrics

---

ğŸ“† **Timeline**


| **Week** | **Focus Areas**                                |
| -------- | ---------------------------------------------- |
| Week 6   | Hyperparameter tuning, extra visualizations    |
| Week 7   | Final testing, interpretability, full write-up |

---

ğŸ“˜ **References**

- Scikit-learn Documentation
  ğŸ”— https://scikit-learn.org/
- UCI Heart Disease Dataset
  ğŸ”— https://archive.ics.uci.edu/ml/datasets/heart+Disease
- GÃ©ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*

---
