{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, classification_report, roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_preparation import load_data, build_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "preprocessor = build_preprocessor(X_train)\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and fit the best models\n",
    "(You can update the parameters below with the best found from GridSearchCV if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (update with best params if available)\n",
    "logreg = LogisticRegression(max_iter=1000, C=1, penalty='l2', class_weight='balanced', solver='liblinear')\n",
    "logreg.fit(X_train_processed, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test_processed)\n",
    "y_proba_logreg = logreg.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# Random Forest (update with best params if available)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train_processed, y_train)\n",
    "y_pred_rf = rf.predict(X_test_processed)\n",
    "y_proba_rf = rf.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# SVM (update with best params if available)\n",
    "svm = SVC(probability=True, C=1, kernel='rbf', class_weight='balanced', random_state=42)\n",
    "svm.fit(X_train_processed, y_train)\n",
    "y_pred_svm = svm.predict(X_test_processed)\n",
    "y_proba_svm = svm.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_test, y_proba_logreg)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_proba_svm)\n",
    "plt.plot(fpr_logreg, tpr_logreg, label=f'Logistic Regression (AUC = {roc_auc_score(y_test, y_proba_logreg):.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_score(y_test, y_proba_rf):.2f})')\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {roc_auc_score(y_test, y_proba_svm):.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "prec_logreg, rec_logreg, _ = precision_recall_curve(y_test, y_proba_logreg)\n",
    "prec_rf, rec_rf, _ = precision_recall_curve(y_test, y_proba_rf)\n",
    "prec_svm, rec_svm, _ = precision_recall_curve(y_test, y_proba_svm)\n",
    "plt.plot(rec_logreg, prec_logreg, label=f'Logistic Regression (AP = {average_precision_score(y_test, y_proba_logreg):.2f})')\n",
    "plt.plot(rec_rf, prec_rf, label=f'Random Forest (AP = {average_precision_score(y_test, y_proba_rf):.2f})')\n",
    "plt.plot(rec_svm, prec_svm, label=f'SVM (AP = {average_precision_score(y_test, y_proba_svm):.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve Comparison')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for ax, y_pred, name in zip(axes, [y_pred_logreg, y_pred_rf, y_pred_svm], ['Logistic Regression', 'Random Forest', 'SVM']):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(f'{name} Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Best Parameters and Scores\n",
    "(Update this table with your actual best parameters from GridSearchCV if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'SVM'],\n",
    "    'ROC-AUC': [roc_auc_score(y_test, y_proba_logreg), roc_auc_score(y_test, y_proba_rf), roc_auc_score(y_test, y_proba_svm)],\n",
    "    'Average Precision': [average_precision_score(y_test, y_proba_logreg), average_precision_score(y_test, y_proba_rf), average_precision_score(y_test, y_proba_svm)],\n",
    "    'Accuracy': [logreg.score(X_test_processed, y_test), rf.score(X_test_processed, y_test), svm.score(X_test_processed, y_test)]\n",
    "})\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can update the model parameters in the cells above with the actual best parameters found by GridSearchCV for more accurate reporting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
